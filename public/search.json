[{"categories":null,"content":"Дисклеймер: Материл носит исключительно информационный характер. Автор не призывает к каким-либо действиям. В этой статье разберём способы анонимизации пользователя, то есть подмены IP-адреса и скрытия трафика при выходе в интернет. Уверен, большинство посетителей и-так знают о Proxy/VPN/Tor, но если хотите поподробнее ознакомиться с каждым из них, то добро пожаловать. В ином случае ждите второй части статьи, где мы поговорим о способах анонимного общения, покупок и плат за услуги, а также узнаем, как установить лучшую (субъективно) ОС для анонимизации. Примечание. Рабочие proxy и VPN постоянно меняются, к тому же их работоспособность зависит от большого количества факторов, поэтому ссылки на подобные сервисы оставлять не буду. ","date":"13-11-2024","objectID":"/articles/anonymity/:0:0","tags":["anonymity"],"title":"Анонимность в сети. Часть I","uri":"/articles/anonymity/"},{"categories":null,"content":"Способы анонимизации\rПожалуй, стоит начать с факта, который каждый наверняка не раз слышал: абсолютной анонимности в современном интернете не существует. Тем не менее, при должном упорстве можно обеспечить себе достойный уровень скрытности, при котором вы найдёте силы договориться со своей паранойей) ","date":"13-11-2024","objectID":"/articles/anonymity/:1:0","tags":["anonymity"],"title":"Анонимность в сети. Часть I","uri":"/articles/anonymity/"},{"categories":null,"content":"Proxy\rProxy — наиболее простая технология, позволяющая скрывать настоящий IP, MAC адреса и прочее. Работает как отдельный пк (сервер), с большой долей вероятности расположенный вне страны пользователя и отправляющий запросы на посещаемый источник от своего имени. То есть вместо того, чтобы напрямую соединить хост с целевым сервисом, прокси-сервер пропускает трафик через себя и устанавливает соединения, выдавая свой IP и скрывая информацию юзера. Важными недостатками технологии являются отсутствие шифрования трафика при использовании бесплатных посредников и весьма вероятное ведение логов, то есть записей посещаемых сайтов, отпечатка браузера, деталей ОС и прочей информации. Ну а совсем недобросовестные провайдеры могут пытаться перехватить данные, которые пользователь вводит на посещаемых ресурсах. Лично я использую этот вариант только для посещения локально-заблокированных ресурсов, но не для подмена личности. И вам советую не ограничиваться лишь одним прокси, если нужно скрыться от посторонних глаз. ","date":"13-11-2024","objectID":"/articles/anonymity/:1:1","tags":["anonymity"],"title":"Анонимность в сети. Часть I","uri":"/articles/anonymity/"},{"categories":null,"content":"VPN\rVPN (Virtual Private Network) — более интересная технология по сравнению с предыдущей. В ней также используются удалённые сервера, но, в отличие от большинства прокси, пакеты дынных (блоки данных / раздробленные данные) проходят этап шифрования. Происходит это так: VPN-клиент на устройстве пользователя шифрует запросы, которые затем отправляются по заранее созданному туннелю на удалённый сервер. Там данные расшифровываются, и запрос идёт уже с IP сервера прямиком к нужному сайту. Затем ответ от этого сайта возвращается к VPN-серверу, где шифруется и передаётся пользователю по тому же туннелю, а VPN-клиент дешифрует данные. В итоге при проходе через туннель данные нельзя “прослушать”, а если и получится, то придётся их расшифровать. Также, само собой, конечный сервис НЕ будет в курсе, что на самом деле запрос отправлялся нами. На следующем рисунке представлена поверхностная схема отправки запроса через VPN Минусы VPN: Важно отметить, что хоть данные идут через зашифрованный туннель, интернет-трафик всё равно проходит через вашего провайдера, а значит этот самый провайдер спокойно фиксирует факт использования как VPN, так и Proxy, и даже Tor’a, что, кстати, будет не сильно подозрительным с текущей политикой РКН :) DNS — система преобразования доменных имён в IP-адреса. Это преобразование, осуществляющееся DNS-серверами провайдеров, происходит, когда вы нажимаете “Enter” в поисковой строке браузера. То есть вместо noisycake.ru будет переход по следующему IP-адресу: 185.199.109.153. А нужно всё это для удобства человека, ведь кому понравится забивать набор октет вместо понятных буквенных символов? Так вот существует следующее понятие: DNS leak или утечка DNS, при которой DNS-запросы идут в обход Proxy/VPN/Tor, из-за чего провайдер видит адреса посещаемых вами сайтов. Она может произойти по нескольким причинам: неправильная настройка или “плохой” VPN, использование сторонних расширений браузера и т.д. Рекомендую ознакомиться с политикой вашего VPN-провайдера, покопаться в настройках, погуглить и запретить ОС обращаться к другим DNS-серверам, кроме как VPN’овским. Опасность\rМогут ли всё-таки “утечь” ваши данные? Однозначно. Ведь на сервере они становятся открытыми, и большинство поставщиков VPN услуг предоставляют их рекламным сервисам (в лучшем случае), а по запросу правоохранительных органов выкатывают им всё имеющееся без серьёзных споров. Особо опасными, как и в случае с прокси, являются бесплатные сервера.\rГлавная проблема VPN. Представим ситуацию: вы — житель прекрасной страны КНР — подключаетесь к VPN-серверу со своего домашнего ПК, IP адрес сетевой карты которого — 103.102.180.1. Сервер отправляет запросы на целевой ресурс, который видит уже другой IP — 217.161.27.2, в то время как ваш провайдер знает только о факте подключения к этому IP, но не о посещаемых сайтах. Казалось бы, никто никогда не узнает, где и кто вы есть на самом деле. Пьянящее чувство свободы слова даёт вам возможность высказать всё, что вы думаете о нынешнем устое, и вы пишите оскорбительный комментарий в адрес правительства КНР в местной соцсети. Спецслужбы, поперхнувшись утренним кофе, негодуют из-за столь неподобающей наглости. Они тут же запрашивают у соцсети ваш IP, получают 217.161.27.2 и пробивают его. Хм, Лондон… Но неужто эти культурные, вежливые любители чая могли так нецензурно выразиться, да ещё и на чистом китайском? Далее спецслужбы запрашивают список пользователей, которые подключались к 217.161.27.2 в определённые дату и время у местных провайдеров. Через одного такого провайдера вы и сидели, а как мы помним, он сохраняет и ваш IP (103.102.180.1), и IP целевого ресурса, коим выступает VPN-сервер, и дату-время обращения к этому ресурсу. И-так, упомянутые адреса сопоставлены. Нужно лишь сделать ещё запрос по личности, скрывающейся за конечным IP. Ага, нашёлся! Теперь осталось самое главное — вежливо объяснить, почему ваш комментарий неуместен в данной ситуации. Короче говоря, ожидайте культурной дискуссии с людьми самой спокойной професси","date":"13-11-2024","objectID":"/articles/anonymity/:1:2","tags":["anonymity"],"title":"Анонимность в сети. Часть I","uri":"/articles/anonymity/"},{"categories":null,"content":"Собственный VPN-сервер\rКратко обсудим тему собственного VPN’а. Данный способ посложнее предыдущих и требует базовых навыков программирования и администрирования. Существуют такие штуки как VPS (Virtual Private Server) и VDS (Virtual Dedicated Server) — по сути синонимичные вещи, а именно виртуальные машины, расположенные на серверах. Вы же знаете, что такое виртуальная машина? Собственно, когда вы покупаете VPS/VDS, вы получаете полноценный пк, которым можете управлять удалённо. Гайдов по поднятию своего VPN’а много и больше, да и ввиду отсутствия личного опыта содержательного контента не получится. Как будет желание, напишу статью и на эту тему, а пока поверхностная инструкция: Покупаем VPS/VDS. Нам хватит 1 ядра и 1гб RAM. Разумеется, при покупке нужно выбирать расположение сервиса вне России. Скорее всего VPS выйдет дешевле, берите его — для нашей цели его более чем достаточно, а переплачивать за VDS смысла не имеет. Устанавливаем на купленном сервере любой тип VPN. Довольно объёмный шаг, который придётся очень долго расписывать. Если есть желание — можете разобраться, погуглив пару десятков страничек, а если нет — ждите отдельной статьи :) - А какой профит-то от своего VPN? Лучше уж не париться и купить подписку на готовое решение. - Когда вы подключаетесь к VPN-серверу через провайдера, параллельно с вами с этого же IP работают и другие люди (сотни, тысячи…), из-за чего сайты начинают относиться к адресу с недоверием. Поэтому главный плюс: отсутствие бесконечных капч, проверок и блокировок со стороны веб-сервисов. При работе через VPN-провайдера также существует вероятность, что ваш местный провайдер заблокирует целый пул IP адресов (то есть все адреса серверов), из-за чего вы больше не сможете пользоваться своей подпиской 😨. - А минусы будут? - Анонимности как таковой вы всё равно не получите. Риски примерно такие же, как и при использовании обычного VPN: утечки, мягкотелость VPS-хостинга, неправильная настройка, сопоставление и пр. ","date":"13-11-2024","objectID":"/articles/anonymity/:1:3","tags":["anonymity"],"title":"Анонимность в сети. Часть I","uri":"/articles/anonymity/"},{"categories":null,"content":"Tor\rЗдесь начинаются настоящие инструменты для анонимности. Разберёмся в том, как работает это чудо и на что стоит обратить внимание. На данный момент Tor является самым мощным средством обеспечения приватности, его работу поддерживают тысячи людей по всей планете. Если раньше он был невыносимо медленным, то сейчас им можно пользоваться достаточно комфортно. Как это работает\rTor (The Onion Router) / Луковая маршрутизация — сеть из прокси-серверов (также называют узлами, реле или нодами), в роли которых обычно выступают пк добровольцев. Каждый пакет данных проходит как минимум следующий путь: user -\u003e клиент Tor -\u003e входная (guard) нода -\u003e промежуточная (middle) нода -\u003e выходная (exit) нода -\u003e целевой ресурс. Инфо\rВсе активные узлы находятся в открытом доступе и каждый час публикуются в консенсусе (consensus) особыми девятью узлами, называемыми управляющими серверами (Directory Authorities).\rПри подключении к сети тор цепочка нод выбирается случайно, при этом меняется каждые 10 минут. Вдобавок перед отправкой пакеты шифруются столько раз, сколько узлов в цепочке, и у каждого узла есть свой ключ, дешифрующий только определённый уровень. Таким образом каждая нода будет снимать один слой шифрования и передавать следующей уже от своего имени (поэтому называется луковой маршрутизацией), вплоть до выходной, где данные становятся девственно чистыми. В итоге каждый узел знает адреса только двух соседних сегментов, благодаря чему выходной узел не обладает информацией об исходном пользователе. Ответ на запрос повторят ту же самую цепочку, но в обратном порядке: по ходу прохождения через узлы накладываются уровни шифрования, а дешифровка происходит в тор-клиенте на пк пользователя. Почему же используется только три узла в цепочке? Неужели больше — не лучше? Пожалуй, нет. Больше узлов = больше нагрузки на сеть Tor, поэтому такое количество точек в цепи нужно для баланса между анонимностью и производительностью. Мосты\rСуществует закрытый список нод, которые называются мостами. Их также поддерживают добровольцы, вот только список мостов не публичный. Так зачем они нужны? Неужели обычных реле уже не хватает? А дело в том, что раз список нод публичный, то его могут увидеть все, в том числе, к примеру, Роскомнадзор, который и заставляет российских провайдеров блокировать все возможные ноды, а также сайты, связанные с тором. Подобная ситуация происходит во многих странах, поэтому разработчики луковой сети придумали способ обхода данной проблемы: непубликуемые в общем доступе узлы. При использовании моста цепочка-путь данных от юзера до целевого ресурса немного меняется. Теперь она выглядит так: user -\u003e клиент Tor -\u003e мост (bridge) -\u003e промежуточная нода -\u003e выходная нода -\u003e целевой ресурс. Инфо\rПомните, мы говорили о девяти управляющих серверах? Есть и десятый, который занимается актуализацией списка рабочих мостов. Наш герой без плаща…\rИнтересный факт: На сегодняшний день доля мостов составляет около 20% от общего числа узлов. Ознакомиться с сегодняшним количеством узлов и другими метриками можно на официальном сайте: https://metrics.torproject.org/ Подключаемый транспорт\rМосты используются вместе с подключаемым транспортом (pluggable transport) — инструментами, использующимися для обхода цензуры и скрытия факта использования тора. Сегодня в браузере Tor можно увидеть 4 вида подключаемого транспорта, а именно: Мост Описание, функционал obfs4 Делает Tor-трафик похожим на случайные данные, чтобы его нельзя было распознать с помощью DPI (глубокой проверки пакетов), часто используемой для обнаружения и блокировки Tor. Именно этот мост вы скорее всего получите при запросе meek Перенаправляет Tor-трафик через крупные облачные платформы, такие как Google, Microsoft или Amazon, что делает его похожим на обычный HTTPS-трафик Snowflake Постоянно меняющиеся прокси, управляемые волонтёрами и настроенными так, чтобы сделать вид, что пользователь совершает видеозвонок, а не использует Tor WebTunnel Маскирует подключение к Tor так, чтобы оно выглядело, будто польз","date":"13-11-2024","objectID":"/articles/anonymity/:1:4","tags":["anonymity"],"title":"Анонимность в сети. Часть I","uri":"/articles/anonymity/"},{"categories":null,"content":"Связки нескольких способов\rFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF ","date":"13-11-2024","objectID":"/articles/anonymity/:1:5","tags":["anonymity"],"title":"Анонимность в сети. Часть I","uri":"/articles/anonymity/"},{"categories":null,"content":"Советы\rПерейдём к незамысловатым советам, которые помогут вам оставаться анонимными, и подведём промежуточные итоги. Не устанавливайте дополнительные плагины и расширения в браузер Tor. Подобные дополнения дают уникальный “отпечаток” браузеру, такие как изменения заголовков запросов, действий на веб-сайтах, что может быть использовано для вашего отслеживания. Не открывайте скаченные файлы, пока находитесь в сети Tor. Они могут содержать скрипты, самооткрывающиеся ссылки и прочие фокусы, которых вы можете даже не заметить. Для подобных действий лучше использовать отдельную виртуальную машину, не имеющей доступа в интернет и не содержащей никакой критически важной для вас информации. Не заходите через тор в свои аккаунты из обычной жизни, не используйте и не распространяйте свои личные данные и не общайтесь со своими знакомыми через новые анонимные аккаунты. Шифруйте диски. Банальный, но важный совет, которым многие пренебрегают: всегда придумывайте разные пароли, а лучше генерируйте и храните их в проверенной оффлайн программе по типу KeePass. Также можете сохранить пару важных паролей (доступ к системе/дешифровка диска/доступ к базе данных паролей) прямо на бумажке, но нужно постараться спрятать её. Дальше для полных параноиков 👽: Не покупайте физические сим-карты для одноразовых аккаунтов. Даже в переходах метро. Гораздо лучше покупать одноразовые номера в соответствующих сервисах. На каждом форуме/аккаунте придумывайте себе новую личность. Меняйте свои интересы (либо не выдавайте их совсем), а главное — стиль общения. Выключайте микрофоны и камеры. Сегодня даже ИИ может определить конкретную клавишу лишь по звуку её нажатия, что уж говорить об обученных специалистах. Убирайте мобильный телефон подальше в нужное время. Конечно, просто так, без установки ПО или физических устройств на мобильное устройство, вас прослушать вряд-ли смогут, но лучше пере.. кхм. Не заходите на Фейсбук :) Не платите Bitcoin’ом. В следующей части статьи мы обсудим этот момент подробнее. Не используйте Windows. Подробнее также в следующей части ;) Как раз-таки Tor я использую как основное средство анонимизации. Лучших альтернатив просто не существует. Информации много, поэтому решил разделить статью на две части, и как раз во второй начнётся самое интересное. Жду вашего мнения, и спасибо, что читаете! ","date":"13-11-2024","objectID":"/articles/anonymity/:1:6","tags":["anonymity"],"title":"Анонимность в сети. Часть I","uri":"/articles/anonymity/"},{"categories":null,"content":"Об авторе\rПривет, меня зовут Иван. Я увлекаюсь ЯП Python, сетями, машинным обучением. Учусь в двух вузах: РУДН (2-ой курс) и Финансовый университет при Правительстве РФ (1-ый курс). Хожу на разные мероприятия по типу кейс-чемпионатов, чтобы познакомиться с интересными людьми. 👨‍💻 Студент 📚 Специальности: Компьютерные и информационные науки; Финансы и инвестиции ","date":"08-11-2024","objectID":"/about/:1:0","tags":null,"title":"О нас","uri":"/about/"},{"categories":null,"content":"О блоге\rHFK (Hungry for Knowledge) – онлайн-ресурс, содержащий конспекты, статьи и проекты автора, охватывающие спектр тем, связанных с программированием и не только. Цели проекта: предоставить удобный доступ к материалам и создать портфолио. Планы на будущее: разместить проект, связанный с языком программирования Python; сделать свою первую полноценную статью. Мини-проект (сайт) HFK был выполнен с помощью генератора статических сайтов Hugo и темы FixIt. История блога\rСоздан сайт на основе темы Blowfish\r2024-06-15Добавлено достаточно контента\r2024-07-13После долгого простоя в связи с несовместимостью Blowfish с мобильными устройствами (или ошибками реализации) было решено сменить тему Blowfish -\u003e FixIt\r2024-11-07Куплен домен noisycake.ru\r2024-11-09Начало переноса контента с небольшим форматированием. Принято решение не публиковать большинство старых конспектов\r2024-11-09\r","date":"08-11-2024","objectID":"/about/:2:0","tags":null,"title":"О нас","uri":"/about/"},{"categories":["math"],"content":"Попытка объяснить основы математической статистики на простом языке Предупреждение\rВ процессе написания\r","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:0:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["math"],"content":"Генеральная совокупность и выборка\rГенеральная совокупность (ГС) — это множество всех объектов, относительно которых предполагается делать выводы в рамках конкретного исследования. Выборка — часть генеральной совокупности. Требуется, если невозможно провести исследования над всей генеральной совокупностью. Репрезентативная выборка — такая выборка, в которой все основные признаки генеральной совокупности, из которой извлечена данная выборка, представлены приблизительно в той же пропорции или с той же частотой, что и в этой ГС. Способы выборок: Простейшая случайная выборка. В ней объекты выбираются случайным образом из всей ГС. Стратифицированная выборка. Генеральная совокупность в такой выборке разбивается на страпы (группы) на основе определённого признака/признаков, затем из каждой группы случайным образом берутся элементы. Групповая (кластерная) выборка. Совокупность также разделяется на группы, но не по какому-то признаку, а случайным образом. Следующим шагом выбираются несколько групп, из которых элементы берутся также случайно. ","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:1:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["math"],"content":"Типы переменных\rПеременными выборки называют те или иные признаки объектов, которые собираются исследовать. Они бывают нескольких видов. Количественные — переменные, которые можно измерить (к примеру, рост). Если переменная может принимать любое значение на определённом промежутке, то она называется непрерывной количественной переменной (например, рост в промежутке от 150 до 200). Дискретными переменными называются те, которые могут принять отдельное возможное значение с определённой вероятностью (количество детей в семье). Номинативные (качественные) — также бывают двух видов. Первые — номинальные переменные, использующиеся как имена для групп. Например, можно обозначить группу мужчин за x, а группу женщин за y. Вторые — ранговые переменные, представляющие упорядоченные категории. К примеру, степень удовлетворённости обслуживанием в кафе или порядковый номер бегуна в забеге. ","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:2:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["math"],"content":"Меры центральной тенденции\rГистограмма частот — графическое представление распределения количественного признака. Познакомимся с типами описательных статистик. Меры центральной тенденции — значения, вычисленные тем или иным путём исходя из графика, описывающие множество значений самого графика. Допустим, имеются 1000 значений некоторой количественной переменной. Требуется описать эти данные всего одним числом, содержащим ценную информацию. Мода — значение измеряемого признака, встречающееся наиболее часто. Рассмотрим следующий график. Числом, которое встречается чаще всего, является 172 — оно и будет модой распределения. Исключим одно значение, равное 172. Теперь имеем моду сразу из трёх значений: 167, 170, 172. Медиана — значение признака, которое делит упорядоченное множество данных пополам. При нечётном количестве элементов медианой является середина множества. При чётном же — среднее арифметическое двух центральных значений признака. Возьмём только первые 9 чисел из упорядоченного множества на графике. Имеем след. значения: 157, 159, 161, 164, 165, 166, 167, 167, 167. В данном случае медианой является 165. Среднее значение — среднее арифметическое всех значений признака. Данный показатель (вернее, среднее арифметическое) обладает некоторыми свойствами: Если каждый элемент выборки увеличить на одно и то же число, то и среднее значение увеличится на это число. Если каждый элемент выборки умножить на одно и то же число, то и среднее значение у на это число. Если для каждого значения выборки рассчитать его отклонение от среднего арифметического, то сумма этих отклонений будет равна 0. Обозначение: \\(\\Mu/\\mu\\) — для ГС или \\(\\bar{x}\\) — для выборки Представленное выше распределение симметрично, унимодально (имеет одну моду) и не имеет заметных выбросов, поэтому для его описания можно использовать любую меру. ","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:3:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["math"],"content":"Меры изменчивости\rЧтобы рассчитать показатели, характеризующие изменчивость исследуемого признака, можно использовать следующие меры: Размах (range) — разность между максимальным и минимальным значением распределения. Данная мера использует всего два значения, из-за чего не является достаточно показательной. Обозначение: \\(R\\) Дисперсия — средний квадрат отклонений индивидуальных значений признака от их средней величины. Она вычисляется по следующей формуле: \\(D = \\frac{\\sum(x_i - \\bar{x})^2}{n}\\). Важно уточнить, что данная формула применима только к генеральной совокупности. Для расчёта дисперсии выборки из знаменателя вычитают единицу: \\(D = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\) Обозначение: \\(D\\) или \\(\\sigma^2\\) Среднеквадратичное (стандартное) отклонение — реальное среднее значение отклонений, получаемое извлечением корня из дисперсии. Соответственно, для нахождения, пользуемся формулой: $$ \\sqrt{\\sigma = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}} $$ Обозначение: \\(\\sigma\\) — для ГС или \\(sd\\) — для выборки Разберём некоторые свойства дисперсии: \\(D_{x+c} = D_x\\) \\(sd_{x+c} = sd_x\\) \\(D_{xc} = D_x * x^2\\) \\(sd_{xc} = sd_x * x\\) ","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:4:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["math"],"content":"Квантили распределения, box plot\rКвантили — такие значения признака, которые делят упорядоченные данные на некоторое число равных частей. Квартили — 3 квантиля, которые делят распределение на 4 равные части. Box plot (ящик с усами/боксплот) — график, компактно представляющий одномерное распределение вероятностей. Он показывает: Медиану (средний квартиль на уровне 50%); Верхний квартиль (на уровне 75%); Нижний квартиль (на уровне 25%); Межквартильный размах (МКР — разница между верхним и нижним квартилями); Выбросы, т.е. те значения, которые выходят из промежутка [нижний квартиль - 1,5 * МКР; верхний квартиль + 1,5 * МКР] ","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:5:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["math"],"content":"Нормальное распределение\rНормальное распределение (распределение Гаусса) — унимодальное и симметричное распределение, в котором отклонения значений от стандартного равновероятны и подчиняются следующему вероятностному закону: в диапазоне \\(\\pm\\sigma\\) стандартных отклонений от среднего значения находится 34.1*2 ≈ 64% наблюдений в диапазоне \\(\\pm2\\sigma\\) стандартных отклонений от среднего значения (34.1 + 13.6)*2 ≈ 95% наблюдений в диапазоне \\(\\pm3\\sigma\\) стандартных отклонений от среднего значения находится (34.1 + 13.6 + 2.1)*2 ≈ 100% наблюдений за последним диапазоном находится ≈ 0.1% наблюдений Z-преобразование (стандартизация) — преобразование распределения таким образом, чтобы его среднее значение стало равно 0, а среднеквадратичное отклонение — 1. Осуществляется преобразование следующим образом: $$ z_i = \\frac{x_i - \\bar{x}}{\\sigma} $$ При Z-преобразовании форма распределения никак не меняется: Другими словами, преобразование дает понять в скольких стандартных отклонениях находится отдельно взятое значение. Например, человек с ростом 186,2 находится примерно в 1.4 стандартных отклонениях от среднего (1.4*8 = 11,2, именно на столько отличается рост этого человека от среднего). Z-преобразование позволяет найти процент наблюдений, находящийся в произвольном диапазоне. Пусть \\(\\bar{x}=150\\), \\(sd=8\\). Требуется найти долю значений, превышающих 154. В таком случае \\(z = \\frac{154 - 150}{8} = 0,5\\). Воспользуемся следующей таблицей. В ней Значения z представлены для значений не больших чем z, но нам нужно как раз обратное, поэтому вычитаем найденное число из единицы, получаем ≈ 0.3. Для нахождения долей также можно воспользоваться калькулятором ","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:6:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["math"],"content":"Центральная предельная теорема\rЦентральная предельная теорема (ЦПТ) утверждает, что, при условии достаточного размера выборки, распределение выборочных средних приблизительно нормально со средним равным среднему признака в ГС, даже если распределение генеральной совокупности не является нормальным. Сайт с симуляцией данных для центральной предельной теоремы. Предположим, что некоторый признак распределён нормально в ГС и имеет \\(\\mu = 15\\) Многократно извлечём выборки по 50 наблюдений в каждой из ГС и взглянем на них. Внутри каждой рассчитано среднее значение и стандартное отклонение. Как видно, оба показателя варьируются от выборки к выборке, причём довольно сильно. Теперь построим распределение выборочных средних значений. Взглянем на следующую картинку. Наше среднее выборочных средних (да-да) достаточно близко к среднему ГС. Стандартное отклонение такого распределения называется ошибкой среднего и показывает, насколько в среднем выборочное значение отклоняется от среднего в ГС. Теперь увеличим объём каждой выборки до 500 наблюдений. Видим, что, во-первых, распределение в каждой выборке стало напоминать распределение в ГС, а во-вторых, выборочные оценки стали гораздо точнее. Снова вернёмся к распределению выборочных средних показателей. Как и ожидалось, стандартная ошибка значительно уменьшилась. Стандартная ошибка — мера оценки математического ожидания генеральной совокупности \\(\\mu\\) на основании выборочного среднего \\(\\bar{x}\\). Вычисляется она по следующей формуле: $$ se = \\frac{\\sigma}{\\sqrt{N}} $$ , где N — число наблюдений ГС. Очевидно, что при увеличении количества наблюдений в выборке и уменьшении стандартного отклонения ГС, стандартная ошибка будет уменьшаться. Для репрезентативных (элементы отобраны случайно) выборок с числом наблюдений больше 30 стандартная ошибка вычисляется похожим образом (при этом будет равна стандартной ошибке ГС): $$ se_x = \\frac{sd_x}{\\sqrt{n}} $$ , где n — число наблюдений выборки. Таким образом, имея на руках только одну выборку, возможно предсказать, как бы вели себя все выборочные средние — они бы распределились вокруг среднего генеральной совокупности со стандартным отклонением равным \\(se\\). Обозначение стандартной ошибки: \\(se\\) ","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:7:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["math"],"content":"Доверительные интервалы для среднего\rДоверительный интервал — интервал, в пределах которого с заданной вероятностью лежат выборочные оценки статистических характеристик ГС (в данном случае — среднее значение). Разберём статистическую задачу. Нужно найти среднее значение (интервал, в котором оно будет с опред. долей вероятности) генеральной совокупности, о которой ничего не известно, зато есть выборка из 64 наблюдений, выборочное среднее которой равно 100, а среднеквадратичное отклонение — 4. Если бы эксперимент повторялся многократно, то все выборочные средние равномерно распределились бы относительно среднего ГС со стандартным отклонением \\(se\\). 95% всех выборочных средних лежали бы в диапазоне: \\(\\bar{x}\\pm 1,96 * \\sigma\\). Так как выборка у нас всего одна, заменим \\(\\sigma\\) на \\(se\\) — стандартную ошибку среднего. Неизвестно, где находится выборочное среднее, но известно, что среднее ГС располагается прямо по центру (вспоминаем центральную предельную теорему). Попробуем случайно поставить несколько выборочных средних и просчитать интервалы. Получим, что с вероятностью 0,95 имеющееся выборочное среднее будет включать среднее ГС. Вычислим границы интервала, в центре которого — выборочное среднее: \\(a = 100 + 1,96 * \\frac{4}{\\sqrt{64}} = 100,98\\) — правая граница; \\(b = 100 - 1,96 * \\frac{4}{\\sqrt{64}} = 99,02\\) — левая граница. И-так, рассчитав интервал таким образом, можно быть на 95% уверенным, что он содержит среднее значение ГС. Увеличивая степень уверенности, расширяется интервал. ","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:8:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["math"],"content":"P-уровень значимости\rНулевая гипотеза (обозн. \\(H_0\\)) — предположение о том, что не существует связи между двумя наблюдаемыми событиями. P-value (p-уровень значимости) — вероятность получить для распределения случайной величины значений такое же или более экстремальное значение (медиана, среднее и т.д.), по сравнению с ранее наблюдаемым, при условии, что нулевая гипотеза верна. Неформально, p-value — вероятность ошибки в случае отклонении нулевой гипотезы. Чем меньше уровень значимости, тем больше оснований отклонить нулевую гипотезу. Считается, что при \\(p \u003c 0,05\\) (что весьма и весьма спорно), можно принимать альтернативную гипотезу. В ином случае — оснований для отклонения нулевой гипотезы недостаточно. Идея статистического вывода — допустим, нулевая гипотеза верна, т.е. никаких различий или взаимосвязей в ГС нет. Теперь можно рассчитать вероятность того, что имеющиеся отклонения были получены абсолютно случайно. Рассмотрим пример. Предположим, что на выздоровление при некотором заболевании в среднем требуется 20 дней, однако был разработали новый препарат, и нужно проверить, можно ли сократить этот срок. Была набрана выборка из 64 пациентов, на которых опробовали новый метод лечения. Оказалось, что средний срок выздоровления сократился до 18,5 дней при стандартном отклонении равным 4. Какой вывод можно сделать основываясь на данных? Нулевая гипотеза \\(H_0\\) — на самом деле никого воздействия новый препарат не оказывает, и среднее значение ГС тех пациентов, кто использует препарат, на самом деле не отличается от 20. Альтернативная гипотеза \\(H_1\\) — препарат влияет на скорость выздоровления, а среднее значение ГС тех, кто использует препарат, не равняется 20. Предположим, что верна нулевая гипотеза, тогда в соответствии с ЦПТ, при многократном повторении эксперимента выборочные средние распределились бы нормальным образом вокруг среднего ГС со стандартной ошибкой среднего \\(se=4/\\sqrt{64}=0.5\\). Выясним, насколько далеко имеющееся выборочное среднее отклонилось от предполагаемого среднего ГС в единицах стандартного отклонения через z-преобразование: \\(z=\\frac{\\bar{x}-\\Mu}{se}=\\frac{18.5 - 20}{0.5}=-3\\). Таким образом, если бы в ГС среднее значение на самом деле равнялось 20, то имеющееся выборочное среднее отклонилось бы от него на \\(-3\\sigma\\) в левую сторону. Воспользуемся свойством нормального распределения, чтобы рассчитать в калькуляторе вероятность такого или еще больше выраженного отклонения от среднего значения. Получается, вероятность отклониться от среднего больше чем на 3 стандартных отклонения равняется приблизительно 0,0027, а значит, можно смело отвергать нулевую гипотезу. Ошибка первого рода (\\(\\alpha\\)-ошибка, ложноположительное заключение) — ситуация, когда отвергнута верная нулевая гипотеза. Ошибка второго рода (\\(\\beta\\)-ошибка, ложноотрицательное заключение) — ситуация, когда принята неверная нулевая гипотеза. ","date":"15-09-2024","objectID":"/notes/basics_of_statistics/:9:0","tags":["math"],"title":"Основы статистики","uri":"/notes/basics_of_statistics/"},{"categories":["python"],"content":" Конспект посвящён объяснению понятия компьютерной памяти и тому, как эта память устроена в языке программирования Python ","date":"18-07-2024","objectID":"/notes/memory_python/:0:0","tags":["python","memory"],"title":"Устройство памяти в Python","uri":"/notes/memory_python/"},{"categories":["python"],"content":"Компьютерная память\rКак можем видеть из схемы ниже, память в компьюетере разделяется на внутреннюю и внешнюю: Посмотрим подробнее на каждый тип памяти. ","date":"18-07-2024","objectID":"/notes/memory_python/:1:0","tags":["python","memory"],"title":"Устройство памяти в Python","uri":"/notes/memory_python/"},{"categories":["python"],"content":"Внутренняя память\rХарактерными особенностями внутренней памяти по сравнению с внешней являются высокое быстродействие и ограниченный объем. Физически внутренняя память компьютера представляет собой интегральные микросхемы, которые размещаются в специальных гнездах на материнской плате. Чем больше размер внутренней памяти, тем более сложную задачу и с большей скоростью может решить компьютер. Внутренняя память подразделяется на: постоянную память оперативную память кэш-память Постоянная память (ROM — read-only memory) — энергозависимая память, использующаяся для долговременного хранения неизменяемого массива данных. Содержание ПЗУ специальным образом закладываестя при его изготовлении для постоянного хранения. Из название как раз можно понять, что данная память предназначена только для чтения. Оперативная память (RAM — Random Access Memory) — в большинстве случаев энергозависимая память, хранящая выполняемый машинный код программ, входные, выходные и промежуточные данные, обрабатываемые процессором в текущем сеансе работы ПК. После выключения питания компьютера, полностью очищается. Микросхемы оперативной памяти монтируются на печатной плате. Каждая такая плата снабжена контактами, расположенными вдоль нижнего края. Для подключения к другим устройствам компьютера такая плата вставляется своими контактами в специальный разъем (слот) на материнской плате. Материнская плата имеет несколько разъемов для модулей оперативной памяти, суммарный объем которых может принимать ряд фиксированных значений, например 2, 4, 8, 16, 32 Гб и более. Оперативная память бывает нескольких типов: SDRAM, DDR, DDR2, DDR3, DDR4, DDR5. Каждый последующий тип памяти представляет собой улучшение предыдущего и позволяет новой памяти работать с большей скоростью. В данный момент в современных компьютерах используется оперативная память типа DDR4 и DDR5. Кэш-память (cache) — промежуточный буфер с быстрым доступом к нему, содержащий информацию, которая может быть запрошена с наибольшей вероятностью. Эта память испольлзуется при обмене данными между процессором и оперативной памятью. Алгоритм ее работы позволяет сократить частоту обращений процессора к оперативной памяти и, следовательно, повысить производительность компьютера. Современные процессоры оснащены кэшем, который состоит зачастую из трех уровней: L1 (первый уровень), L2 (второй уровень), L3 (третий уровень). L1 — наиболее быстрый уровень кэш-памяти, который работает напрямую с ядром процессора, в следствии чего обладает наименьшим временем доступа и работает на частотах, близких процессору. Размер данного кэша обычно не велик, а количество микросхем зачастую привязано к количеству ядер процессора, при этом у каждого ядра кэш свой собственный. Размер блока может варьироваться от 64-256 КБ у десктопов и ноутбуков до 1-2 МБ для серверных решений. Сам L1 тоже имеет свое разделение. Он делится на кэш команд и кэш данных: Первый содержит информацию об операции, которой занимается ЦП, проще говоря, отвечает на вопрос: «Что надо сделать»; Второй хранит в себе данные, над которыми должны производиться вычисления. L2 — второй уровень более масштабный, нежели первый, но в результате, обладает меньшими скоростными характеристиками. Также привязан к ядру и не взаимодействует с остальными. L3 — третий уровень. Он более медленный, нежели два предыдущих, но всё же гораздо быстрее, чем оперативная память. Этот блок уже доступен для всех ядер процессора. На третьем уровне временно хранятся данные, которые хоть и важны для продуктивной работы, но регистры обращаются за этой информацией относительно нечасто. ","date":"18-07-2024","objectID":"/notes/memory_python/:1:1","tags":["python","memory"],"title":"Устройство памяти в Python","uri":"/notes/memory_python/"},{"categories":["python"],"content":"Внешняя память\rНазначение внешней памяти компьютера заключается в долговременном хранении информации любого вида. Выключение питания компьютера не приводит к очистке внешней памяти и её объём в тысячи раз больше объёма внутренней памяти. Минус такой памяти в том, что обращение к ней требует гораздо большего времени. К устройствам внешней памяти относятся: Жёсткие магнитные диски (HDD — Hard Disk Drive) Твердотельные накопители (SSD — Solid State Drive) Оптические диски (CD-ROM, DVD-ROM, Blue-Ray и т.д.) Флеш-накопители Гибкие магнитные диски Наиболее распространенный вариант постоянной памяти — жесткие диски HDD. Они представляют собой один или несколько магнитных дисков, вращающихся с огромной скоростью (от 5 до 12 тысяч оборотов в минуту), и головок, предназначенных для считывания и записи информации. HDD являются надежными носителями информации, позволяют записывать и считывать информацию огромное количество раз. Неудобство в том, что они очень медленные и восприимчивы к ударам, падениям и прочим механическим воздействиям, особенно в момент работы. Почти у каждого уверенного пользователя ПК в наши дни скорее найдётся SSD, чем HDD. Их популярность неудивительна, ведь они имеют гораздо более высокую скорость записи и чтения и невосприимчивы к механическим воздействиям. Их можно было бы назвать идеальными накопителями, если бы не ощутимо конечное количество циклов чтения-записи. ","date":"18-07-2024","objectID":"/notes/memory_python/:1:2","tags":["python","memory"],"title":"Устройство памяти в Python","uri":"/notes/memory_python/"},{"categories":["python"],"content":"Управление памятью в Python\rУправление памятью — это процесс выделения, распределения и координации памяти таким образом, чтобы все программы работали правильно и могли оптимально получать доступ к различным системным ресурсам. Управление памятью также включает в себя и очистку памяти от объектов, которые больше не нужны. Существует два типа управления памятью: ручное и автоматическое. Ручное управление включает в себя, как правило, три этапа: Запрос памяти у операционной системы Работа с ней Возвращение памяти обратно в операционную систему Ручной подход управления (как в C, C++, Pascal и т.д.) позволяет работать с памятью максимально эффективно. Программист точно знает, сколько памяти ему выделено, зачем он её использует, и т.д. Однако помимо преимуществ такой подход имеет и ряд недостатков. Ключевой из них — сложность. Управлять памятью вручную — сложно и тяжело, поскольку легко забыть вернуть память обратно операционной системе, в результате чего возникает утечка: программа держит неиспользуемую память просто так, не давая применять ее для решения других задач. Автоматическое управление памятью (как в Python, Java, JS, C#, Ruby и т.д.) берет на себя самый сложный этап — возвращение памяти обратно операционной системе, когда она уже не требуется. Восстановленная память может использоваться другими объектами. В определённых случаях это менее эффективно, но позволяет сильно сократить трудозатраты и повысить надежность процесса. Python — это язык с автоматическим управлением памятью. Причем для управления ею он использует несколько механизмов. При запуске Python программы создается новый процесс, в рамках которого операционная система выделяет пул ресурсов, включая виртуальное адресное пространство. В эту память загружается интерпретатор Python вместе со всеми необходимыми ему для работы данными, включая код написанной программы. Оставшаяся свободная виртуальная память может использоваться для хранения информации об объектах Python. Для управления этой памятью в CPython используется специальный механизм, который называется аллокатор. Он используется каждый раз, когда вам нужно создать новый объект. Обычно мы в своих программах не оперируем большими объектами. Большая часть наших данных — это числа, строки и т.д., они занимают не такой уж большой объем в расчёте на одно значение. Но зато мы создаем их достаточно часто. И это приводило бы к проблемам, если бы Python абсолютно все такие вызовы транслировал в операционную систему. Системный вызов на выделение памяти — штука трудозатратная, зачастую связанная с переходом в контекст ядра операционной системы. Поэтому одна из главных задач аллокатора Python — оптимизация количества системных вызовов. Инфо\rДля больших объектов (больше 512 байт) Python выделяет память напрямую у ОС. Обычно таких объектов не очень много в рамках программы, и создаются они нечасто. Поэтому накладные расходы на создание таких объектов напрямую в RAM не так высоки.\rАллокатор для малых объектов (не больше 512 байт) использует три уровня абстракции: Блок — кусок памяти, используемый для хранения одного объекта. Пул — страница памяти, содержащий блоки (обычно 4 килобайта). Арена — большой непрерывный кусок памяти, содержащий пулы (обычно 256 килобайт). Блок\rБлок — это кусок памяти, который может содержать только один Python объект фиксированного размера. Размер блока может варьироваться от 8 до 512 байт и должен быть кратен восьми. Все блоки в конкретном пуле имеют одинаковый размер и находятся в одном классе размера, который и определяет размер блока. Запрос памяти в байтах Размер блока в байтах Индекс класса размера 1-8 8 0 9-16 16 1 17-24 24 2 25-32 32 3 33-40 40 4 41-48 48 5 … … … 505-512 512 63 Таким образом, если необходимы: 6 байт, то данные будут помещены в блок размером 8 байт; 42 байта, то данные будут помещены в блок размером 48 байт; и т.д. Пул\rПулы состоят из блоков одного размера. Каждый пул работает по принципу двухсвязного списка с другими пулами того же размера, поэтому алгоритм может с легко","date":"18-07-2024","objectID":"/notes/memory_python/:2:0","tags":["python","memory"],"title":"Устройство памяти в Python","uri":"/notes/memory_python/"},{"categories":["python"],"content":"Очистка памяти\rКак мы уже знаем, язык Python является языком с автоматически управляемой памятью, то есть программисту, пишущему код на Python, не нужно беспокоиться о работе с памятью, в частности заниматься ее освобождением. Как только данные программы (объекты в Python) больше не нужны, Python автоматически освобождает память, которую они занимали. Несмотря на это, понимание того, как работает механизм очистки памяти, может помочь писать более качественный и производительный код. Стандартный интерпретатор Python использует сразу два механизма очистки памяти: Подсчёт ссылок; Сборщик мусора (Garbage Collector, GC). ","date":"18-07-2024","objectID":"/notes/memory_python/:3:0","tags":["python","memory"],"title":"Устройство памяти в Python","uri":"/notes/memory_python/"},{"categories":["python"],"content":"Подсчёт ссылок\rАлгоритм подсчета ссылок — это один из самых простых механизмов очистки памяти. Объекты удаляются как только на них больше нет ссылок. Каждый объект в Python унаследован от базового класса PyObject, который содержит специальное поле Reference Count (ob_refcnt), в котором хранится количество ссылок на данный объект. Как только кто-то начинает ссылаться на объект, значение этого поля увеличивается на единицу. Если по какой-то причине ссылка пропадает, то это поле уменьшается на один. При этом если счетчик ссылок для определенного объекта достигает нуля, то интерпретатор запускает процесс уничтожения объекта. Если удаленный объект содержал ссылки на другие объекты, то эти ссылки также удаляются. Таким образом, удаление одного объекта может повлечь за собой удаление других. Инфо\rМеханизм подсчета ссылок работает в режиме реального времени.\rЧетыре основных сценария, увеличивающих количество ссылок на объект: Создание нового объекта и присвоение его переменной; Присвоение уже существующего объекта переменной; Передача объекта в функцию в качестве аргумента; Добавление объекта в список, множество, словарь и т.д. Четыре основных сценария, уменьшающих количество ссылок на объект: Удаление объекта из области видимости функции после ее завершения; Удаление переменной с помощью оператора del; Переприсваивание переменной нового значения; Удаление объекта из списка, множества, словаря и т.д. Для получения количества ссылок на заданный объект используется функция getrefcount() из модуля sys. import sys nums = [1, 2, 3] print(sys.getrefcount(nums)) # Вывод: 2 Когда мы вызываем функцию getrefcount() для получение количества ссылок на объект, мы увеличиваем количество ссылок на объект на один, так как передаем nums в качестве аргумента в функцию. Поэтому счетчик ссылок равен 2. Это означает, что и переменная nums, и функция getrefcount() ссылаются на один и тот же список [1, 2, 3]. Алгоритм подсчета ссылок очень простой и эффективный, но у него есть один большой недостаток. Он не умеет определять циклические ссылки. Приведённый ниже код создаёт циклические ссылки, так как nums1 содержит ссылку на nums2, в то время как nums2 содержит ссылку на nums1. Таким образом, счетчики ссылок у nums1 и nums2 никогда не будут равны нулю. nums1 = [1, 2, 3] nums2 = [4, 5] nums1.append(nums2) nums2.append(nums1) Именно из-за этого в Python существует дополнительный механизм очистки памяти — сборщик мусора (Garbage Collector, GC), который следит за объектами с потенциальными циклическими ссылками. Инфо\rВ Python алгоритм подсчета ссылок является фундаментальным и не может быть отключен, тогда как сборщик мусора (GC) опционален и может быть отключен.\rКоличество ссылок на определенный объект иногда может оказаться заметно больше, чем кажется на первый взгляд. Дело в том, что многие неизменяемые объекты уже используются, например, в реализациях встроенных функций и типов данных. Объекты, относящиеся к изменяемым типам данных данной особенности не подвержены, так как изменение такого объекта в одной части программы привело бы к его изменению в другой части программы. import sys print(sys.getrefcount(0)) # число 0 print(sys.getrefcount(1)) # число 1 print(sys.getrefcount('')) # пустая строка print(sys.getrefcount(())) # пустой кортеж # Возможный вывод: 164 84 58 1257 Счетчик ссылок подвержен проблемам в многопоточной среде, которые могут приводить к некорректности обновления этого счетчика из разных потоков и, следовательно, к удалению объектов, на которые еще существуют ссылки. Чтобы этого избежать, CPython использует GIL — Global Interpreter Lock. Каждый раз, когда происходит работа с памятью, GIL — как глобальная блокировка — препятствует выполнению этих действий одновременно из двух потоков. Он гарантирует, что сначала отработает один, потом другой. ","date":"18-07-2024","objectID":"/notes/memory_python/:3:1","tags":["python","memory"],"title":"Устройство памяти в Python","uri":"/notes/memory_python/"},{"categories":["python"],"content":"Сборщик мусора\rВ отличие от алгоритма подсчета ссылок, сборщик мусора не работает в режиме реального времени и запускается периодически. Каждый запуск сборщика создаёт микропаузы в работе программы, поэтому Python использует различные эвристики для определения частоты запуска сборщика мусора. Сборщик мусора разделяет все объекты на 3 поколения (нулевое, первое и второе). Новые объекты попадают в нулевое поколение. Если новый объект выживает в процессе сборки мусора, то он перемещается в следующее поколение. Чем старше поколение, тем реже оно сканируется на сборку мусора. Так как новые объекты зачастую имеют очень маленький срок жизни (являются временными), то имеет смысл проверять их чаще, чем те, которые уже прошли через несколько этапов сборки мусора. В каждом поколении есть специальный порог срабатывания, при достижении которого срабатывает процесс сборки мусора. Если сразу несколько поколений преодолели порог, то выбирается наиболее старшее поколение, так как сборка мусора в старших поколениях включает в себя также сборку мусора и в младших поколениях. Основной источник: https://stepik.org/course/82541/syllabus Дополнительные источники: Habr Market.Marvel.ru GitHub ","date":"18-07-2024","objectID":"/notes/memory_python/:3:2","tags":["python","memory"],"title":"Устройство памяти в Python","uri":"/notes/memory_python/"},{"categories":["python"],"content":"Всё про нотацию Big O на примерах базовых коллекций в Python Big O — нотация, использующаяся в программировании, информатике для описания сложности алгоритмов. Она характеризует скорость роста времени выполнения алгоритма с ростом объёма входных данных, используя для оценки верхнюю границу (наихудший исход). Примеры нотаций Big O в порядке убывания скорости выполнения соответствующих им алгоритмов: O(1): Константная сложность. Читается как “сложность порядка 1”. Время выполнения алгоритма не зависит от размера входных данных, то есть если даже алгоритм выполняется постоянно в 3 шага, то он будет не O(3), а O(1). Является идеальной с точки зрения производительности, однако зачастую недостижима. Примеры: Доступ к элементу в массиве по индексу; Вставка или удаление элемента в конец списка (очереди) фиксированной длины. O(log n): Логарифмическая сложность. Время выполнения алгоритма растет медленно с увеличением размера входных данных. Например, бинарный поиск в отсортированном массиве. Пример: Бинарный поиск. В этом алгоритме на каждом шаге половина данных отсекается, и поиск продолжается в оставшейся половине. Это означает, что при увеличении размера входных данных вдвое, бинарный поиск требует всего одного дополнительного шага. O(n): Линейная сложность. Читается как “сложность порядка n”. Время выполнения алгоритма пропорционально размеру входных данных. Пример: Поиск максимального значения в списке: def find_max(my_list): max_num = my_list[0] for i in range(len(my_list)): if my_list[i] \u003e max_num: max_num = my_list[i] return max_num O(n log n): Линейно-логарифмическая сложность. Время выполнения алгоритма растет быстрее, чем линейно, но медленнее, чем квадратично. Пример: Сортировка слиянием. O(n^2): Квадратичная сложность. Примеры: Сортировка пузырём; Поиск суммы всех пар элементов списка: def pairs_sum(my_list): summ = 0 for i in range(my_list): for j in range(my_list): summ += my_list[i] + my_list[j] return summ O(n^3): Кубическая сложность. Пример: Алгоритмы, имеющие три вложенных цикла. O(2^n): Экспоненциальная сложность. Она обычно не является оптимальным решением из-за своей высокой вычислительной нагрузки при увеличении размера входных данных. Пример: Алгоритмы, использующие рекурсию без оптимизации (рекурсивное вычисление чисел Фибоначчи). O(n!): Факториальная сложность. Это самая высокая степень роста времени выполнения алгоритма. Этот тип сложности встречается, например, при переборе всех возможных комбинаций элементов, что делает его чрезвычайно неэффективным для больших значений n. Пример: Перебор всех перестановок элементов массива. ","date":"20-05-2024","objectID":"/notes/big_o/:0:0","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"},{"categories":["python"],"content":"График сложностей алгоритмов\r","date":"20-05-2024","objectID":"/notes/big_o/:0:1","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"},{"categories":["python"],"content":"Несущественное не учитывается\rПри оценке сложности алгоритмов лучше игнорировать константы и несущественные части, от которых скорость выполнения практически не зависит. Например, при оценке 5n^2 + 3n + 2 можно откинуть 5, 3n, 2. В результате мы получим O(n^2). Или при оценке n^2 + n + log(n) оставляем самую значимую часть (перемененную с наибольшей степенью) и получаем тот жеO(n^2). ","date":"20-05-2024","objectID":"/notes/big_o/:0:2","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"},{"categories":["python"],"content":"Сложность операций в Python\rРассмотрим некоторые операции, которые часто используют для базовых структур в языке программирования Python. n — размер структуры данных ","date":"20-05-2024","objectID":"/notes/big_o/:1:0","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"},{"categories":["python"],"content":"Списки:\rОперация Пример Сложность Примечание Получение элемента l[i] O(1) Присваивание значения элементу l[i] = 0 O(1) Размер списка len(l) O(1) Добавление элемента в конец списка l.append(5) O(1) Скорее всего это неверно Удаление последнего элемента l.pop() O(1) Аналогично l.pop(-1) Очищение списка l.clear() O(1) Аналогично l = [] Добавление нескольких элементов l1.extend(l2) O(len(n)) Прямая зависимость с размером l2 Создание списка list(l) O(n) Прямая зависимость с разером l Получение среза l[a:b] O(n) O(a - b) Сравнение списков l1 == l2 O(n) Вставка через срез l[a:b] O(n) Проверка наличия элемента в списке x is/not in l O(n) Тот же перебор элементов Поверхностное копирование списка l.copy() O(n) Аналогично l[:] Удаление элемента через del del l[i] O(n) Перебор до совпадения индексов, а значит зависит от i Удаление элемента через remove l.remove(...) O(n) Удаление элемента через pop l.pop(i) O(n) O(n-i) Получение крайнего значения min(l)/max(l) O(n) Снова перебор элементов Получение обратного списка l.reverse() O(n) Перебор for i in l: O(n) Сортировка l.sort() O(n * log(n)) Или sorted(l) Умножение списка на константу k*l O(k*n) 5*l =\u003e O(n), len(l)*l =\u003e O(n^2) ","date":"20-05-2024","objectID":"/notes/big_o/:1:1","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"},{"categories":["python"],"content":"Кортежи:\rКортежи — те же самые списки, только неизменяемые. Поэтому к ним применимы все операции, не изменяющие структуру данных, и они имеют такие же нотации сложности, как и списки. ","date":"20-05-2024","objectID":"/notes/big_o/:1:2","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"},{"categories":["python"],"content":"Множества:\rОперация Пример Сложность Примечание Размер множества len(s) O(1) Добавление элемента s.add(5) O(1) Проверка наличия элемента в множестве x is/not in s O(1) Удаления элемента через discard s.discard(...) O(1) Удаления элемента через remove s.remove(...) O(1) Удаления элемента через pop s.pop() O(1) Удаляемый элемент выбирается случайно Очищение множества s.clear() O(1) Аналогично s = set() Создание множества set(...) O(n) Сравнение множеств через ==, != s != t O(n) Сравнение множеств через \u003c=, \u003c s \u003c= t O(n) Аналогично s.issubset(t) Сравнение множеств через \u003e=, \u003e s \u003e= t O(n) Аналогично s.issuperset(t) Объединение s | t O(n) Аналогично s.union(t) Пересечение s \u0026 t O(n) Аналогично s.intersection(t) Разность s - t O(n) Аналогично s.difference(t) Симметрическая разность s ^ t O(n) Аналогично s.symmetric_difference(t) Перебор for i in s: O(n) Копирование s.copy() O(n) ","date":"20-05-2024","objectID":"/notes/big_o/:1:3","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"},{"categories":["python"],"content":"Неизменяемые множества\rПоддерживают все операции обычного множества за исключением тех, который изменяют структуру данных, и имеют те же нотации сложности, как у изменяемых множеств. ","date":"20-05-2024","objectID":"/notes/big_o/:1:4","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"},{"categories":["python"],"content":"Словари\rОперация Пример Сложность Примечание Получение элемента d[key] O(1) Добавление элемента/ Изменение значения d[key] = val O(1) Размер словаря len(d) O(1) Удаление элемента через del del d[key] O(1) Удаление элемента через popitem d.popitem() O(1) Удаляемый элемент выбирается случайно Удаление элемента через pop d.pop(key) O(1) get() и setdefault() d.get(key) O(1) Очищение словаря d.clear O(1) Аналогично s = {} или s = dict() Получение списка ключей/значений d.keys() O(1) Создание словаря dict(...) O(n) Перебор элементов for key in d: O(n) Для .keys(), .values(), .items() ","date":"20-05-2024","objectID":"/notes/big_o/:1:5","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"},{"categories":["python"],"content":"Прочие обозначения\rКроме обозначения “Big O”, существуют другие обозначения для оценки сложности алгоритмов: Big Theta (Θ): Big Theta также оценивает верхнюю и нижнюю границы временной сложности алгоритма, но описывает точную сложность, а не только наихудший случай, как Big O. Θ(f(n)) обозначает, что время выполнения алгоритма ограничено функцией f(n) как сверху, так и снизу. Big Omega (Ω): Big Omega оценивает нижнюю границу временной сложности алгоритма. Ω(f(n)) говорит о том, что алгоритм выполнится не быстрее, чем функция f(n). Little O (o): Little O представляет собой верхнюю границу, которая строже, чем Big O. Если f(n) является o(g(n)), это означает, что время выполнения алгоритма ограничивается функцией g(n), но алгоритм работает быстрее, чем g(n). Little Omega (ω): Little Omega представляет собой нижнюю границу, которая строже, чем Big Omega. Если f(n) является ω(g(n)), это означает, что алгоритм работает медленнее, чем g(n), но не медленнее, чем f(n). ","date":"20-05-2024","objectID":"/notes/big_o/:2:0","tags":["big O","algorithms","python"],"title":"Big O","uri":"/notes/big_o/"}]